{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stacked Autoencoder : A stacked autoencoder is a neural network that consists of several layers of sparse autoencoders where output of each hidden layer is connected to the input of the successive hidden layer.\n"
      ],
      "metadata": {
        "id": "9mDBCiBtUtEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "wKEb6q3ag5ym"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries :\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset :\n",
        "\n",
        "movies = pd.read_csv('/content/drive/MyDrive/AutoEncoders/ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('/content/drive/MyDrive/AutoEncoders/ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/AutoEncoders/ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n"
      ],
      "metadata": {
        "id": "xKoDWHJMhLFz"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movies[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPrY5BGzDc3u",
        "outputId": "f63af7fe-07c3-472e-df4b-98519004c6bf"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0                                   1                             2\n",
            "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
            "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
            "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
            "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
            "4  5  Father of the Bride Part II (1995)                        Comedy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(users[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erjYBD5pDgrz",
        "outputId": "1b97ff1d-6bc5-4c21-f2bb-1b1902a0e962"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0  1   2   3      4\n",
            "0  1  F   1  10  48067\n",
            "1  2  M  56  16  70072\n",
            "2  3  M  25  15  55117\n",
            "3  4  M  45   7  02460\n",
            "4  5  M  25  20  55455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ratings[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpQEmIPsDkyE",
        "outputId": "ee7e5db2-fcbe-4407-8e28-4289e19b55c5"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0     1  2          3\n",
            "0  1  1193  5  978300760\n",
            "1  1   661  3  978302109\n",
            "2  1   914  3  978301968\n",
            "3  1  3408  4  978300275\n",
            "4  1  2355  5  978824291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and Test Sets :\n",
        "\n",
        "training_set = pd.read_csv('/content/drive/MyDrive/AutoEncoders/ml-1m/training_set.csv', delimiter='\\t')\n",
        "training_set = np.array([row.split(',') for row in training_set['User,Movie,Rating,Timestamp']], dtype=int)\n",
        "\n",
        "\n",
        "test_set = pd.read_csv('/content/drive/MyDrive/AutoEncoders/ml-1m/test_set.csv', delimiter='\\t')\n",
        "test_set = np.array([row.split(',') for row in test_set['User,Movie,Rating,Timestamp']], dtype=int)\n"
      ],
      "metadata": {
        "id": "DwYlokMZ10Z2"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_set[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TZQuDmF9p7N",
        "outputId": "fd29a137-a663-4657-dd3e-c460b799926a"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[        1       661         3 978302109]\n",
            " [        1       914         3 978301968]\n",
            " [        1      3408         4 978300275]\n",
            " [        1      2355         5 978824291]\n",
            " [        1      1287         5 978302039]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_set[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByFNiyZSD4FC",
        "outputId": "41707665-fcbb-46c1-8183-184cd29ce68d"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[        1      1193         5 978300760]\n",
            " [        1      1197         3 978302268]\n",
            " [        1      2804         5 978300719]\n",
            " [        1       595         5 978824268]\n",
            " [        1       938         4 978301752]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the number of users and movies\n",
        "\n",
        "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0])))\n",
        "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))\n",
        "\n",
        "print(nb_users)\n",
        "print(nb_movies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYcQb6gk3x4q",
        "outputId": "19b6e660-788e-4b5c-e7dc-b5aee5a8f7ff"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6040\n",
            "3952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the data into an array with users in lines and movies in columns\n",
        "\n",
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1, nb_users + 1):\n",
        "    id_movies = data[:, 1] [data[:, 0] == id_users]\n",
        "    id_ratings = data[:, 2] [data[:, 0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies - 1] = id_ratings\n",
        "    new_data.append(list(ratings))\n",
        "  return new_data\n",
        "\n",
        "\n",
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "metadata": {
        "id": "hzYAUTam9YAy"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_set[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcOrfA2CAwpR",
        "outputId": "56edb4d0-5ebf-4cda-fd36-959886f9ba06"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 0., 0.,  ..., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the data into Torch tensors\n",
        "\n",
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "metadata": {
        "id": "RgJsEFzFFx84"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the architecture of the Neural Network\"\"\"\n",
        "\n",
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(SAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "sae = SAE()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "metadata": {
        "id": "Wx7WDFSCTiPl"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the SAE\n",
        "\n",
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "  train_loss = 0\n",
        "  s = 0.\n",
        "  for id_user in range(nb_users):\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    target = input.clone()\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "      output = sae(input)\n",
        "      target.require_grad = False\n",
        "      output[target == 0] = 0\n",
        "      loss = criterion(output, target)\n",
        "      mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "      loss.backward()\n",
        "      train_loss += np.sqrt(loss.data*mean_corrector)\n",
        "      s += 1.\n",
        "      optimizer.step()\n",
        "  print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzx2vCHCTloB",
        "outputId": "d0a81c59-07d6-40ac-8e51-965efbf84546"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1loss: tensor(1.3478)\n",
            "epoch: 2loss: tensor(1.0100)\n",
            "epoch: 3loss: tensor(0.9902)\n",
            "epoch: 4loss: tensor(0.9833)\n",
            "epoch: 5loss: tensor(0.9801)\n",
            "epoch: 6loss: tensor(0.9786)\n",
            "epoch: 7loss: tensor(0.9772)\n",
            "epoch: 8loss: tensor(0.9766)\n",
            "epoch: 9loss: tensor(0.9760)\n",
            "epoch: 10loss: tensor(0.9757)\n",
            "epoch: 11loss: tensor(0.9753)\n",
            "epoch: 12loss: tensor(0.9750)\n",
            "epoch: 13loss: tensor(0.9749)\n",
            "epoch: 14loss: tensor(0.9747)\n",
            "epoch: 15loss: tensor(0.9743)\n",
            "epoch: 16loss: tensor(0.9743)\n",
            "epoch: 17loss: tensor(0.9743)\n",
            "epoch: 18loss: tensor(0.9741)\n",
            "epoch: 19loss: tensor(0.9739)\n",
            "epoch: 20loss: tensor(0.9739)\n",
            "epoch: 21loss: tensor(0.9738)\n",
            "epoch: 22loss: tensor(0.9736)\n",
            "epoch: 23loss: tensor(0.9735)\n",
            "epoch: 24loss: tensor(0.9729)\n",
            "epoch: 25loss: tensor(0.9724)\n",
            "epoch: 26loss: tensor(0.9717)\n",
            "epoch: 27loss: tensor(0.9708)\n",
            "epoch: 28loss: tensor(0.9702)\n",
            "epoch: 29loss: tensor(0.9690)\n",
            "epoch: 30loss: tensor(0.9678)\n",
            "epoch: 31loss: tensor(0.9677)\n",
            "epoch: 32loss: tensor(0.9675)\n",
            "epoch: 33loss: tensor(0.9662)\n",
            "epoch: 34loss: tensor(0.9646)\n",
            "epoch: 35loss: tensor(0.9643)\n",
            "epoch: 36loss: tensor(0.9628)\n",
            "epoch: 37loss: tensor(0.9641)\n",
            "epoch: 38loss: tensor(0.9635)\n",
            "epoch: 39loss: tensor(0.9629)\n",
            "epoch: 40loss: tensor(0.9637)\n",
            "epoch: 41loss: tensor(0.9611)\n",
            "epoch: 42loss: tensor(0.9587)\n",
            "epoch: 43loss: tensor(0.9580)\n",
            "epoch: 44loss: tensor(0.9563)\n",
            "epoch: 45loss: tensor(0.9540)\n",
            "epoch: 46loss: tensor(0.9513)\n",
            "epoch: 47loss: tensor(0.9507)\n",
            "epoch: 48loss: tensor(0.9494)\n",
            "epoch: 49loss: tensor(0.9493)\n",
            "epoch: 50loss: tensor(0.9464)\n",
            "epoch: 51loss: tensor(0.9447)\n",
            "epoch: 52loss: tensor(0.9444)\n",
            "epoch: 53loss: tensor(0.9448)\n",
            "epoch: 54loss: tensor(0.9448)\n",
            "epoch: 55loss: tensor(0.9431)\n",
            "epoch: 56loss: tensor(0.9410)\n",
            "epoch: 57loss: tensor(0.9393)\n",
            "epoch: 58loss: tensor(0.9404)\n",
            "epoch: 59loss: tensor(0.9375)\n",
            "epoch: 60loss: tensor(0.9356)\n",
            "epoch: 61loss: tensor(0.9361)\n",
            "epoch: 62loss: tensor(0.9331)\n",
            "epoch: 63loss: tensor(0.9343)\n",
            "epoch: 64loss: tensor(0.9307)\n",
            "epoch: 65loss: tensor(0.9281)\n",
            "epoch: 66loss: tensor(0.9265)\n",
            "epoch: 67loss: tensor(0.9307)\n",
            "epoch: 68loss: tensor(0.9274)\n",
            "epoch: 69loss: tensor(0.9251)\n",
            "epoch: 70loss: tensor(0.9223)\n",
            "epoch: 71loss: tensor(0.9266)\n",
            "epoch: 72loss: tensor(0.9261)\n",
            "epoch: 73loss: tensor(0.9208)\n",
            "epoch: 74loss: tensor(0.9177)\n",
            "epoch: 75loss: tensor(0.9207)\n",
            "epoch: 76loss: tensor(0.9198)\n",
            "epoch: 77loss: tensor(0.9158)\n",
            "epoch: 78loss: tensor(0.9141)\n",
            "epoch: 79loss: tensor(0.9173)\n",
            "epoch: 80loss: tensor(0.9159)\n",
            "epoch: 81loss: tensor(0.9126)\n",
            "epoch: 82loss: tensor(0.9111)\n",
            "epoch: 83loss: tensor(0.9138)\n",
            "epoch: 84loss: tensor(0.9147)\n",
            "epoch: 85loss: tensor(0.9116)\n",
            "epoch: 86loss: tensor(0.9091)\n",
            "epoch: 87loss: tensor(0.9084)\n",
            "epoch: 88loss: tensor(0.9101)\n",
            "epoch: 89loss: tensor(0.9089)\n",
            "epoch: 90loss: tensor(0.9073)\n",
            "epoch: 91loss: tensor(0.9067)\n",
            "epoch: 92loss: tensor(0.9093)\n",
            "epoch: 93loss: tensor(0.9078)\n",
            "epoch: 94loss: tensor(0.9062)\n",
            "epoch: 95loss: tensor(0.9049)\n",
            "epoch: 96loss: tensor(0.9062)\n",
            "epoch: 97loss: tensor(0.9079)\n",
            "epoch: 98loss: tensor(0.9058)\n",
            "epoch: 99loss: tensor(0.9037)\n",
            "epoch: 100loss: tensor(0.9032)\n",
            "epoch: 101loss: tensor(0.9044)\n",
            "epoch: 102loss: tensor(0.9039)\n",
            "epoch: 103loss: tensor(0.9022)\n",
            "epoch: 104loss: tensor(0.9020)\n",
            "epoch: 105loss: tensor(0.9029)\n",
            "epoch: 106loss: tensor(0.9026)\n",
            "epoch: 107loss: tensor(0.9008)\n",
            "epoch: 108loss: tensor(0.9021)\n",
            "epoch: 109loss: tensor(0.9025)\n",
            "epoch: 110loss: tensor(0.9011)\n",
            "epoch: 111loss: tensor(0.9001)\n",
            "epoch: 112loss: tensor(0.8996)\n",
            "epoch: 113loss: tensor(0.9006)\n",
            "epoch: 114loss: tensor(0.9016)\n",
            "epoch: 115loss: tensor(0.9001)\n",
            "epoch: 116loss: tensor(0.8987)\n",
            "epoch: 117loss: tensor(0.8993)\n",
            "epoch: 118loss: tensor(0.9027)\n",
            "epoch: 119loss: tensor(0.9009)\n",
            "epoch: 120loss: tensor(0.8988)\n",
            "epoch: 121loss: tensor(0.8985)\n",
            "epoch: 122loss: tensor(0.8991)\n",
            "epoch: 123loss: tensor(0.8985)\n",
            "epoch: 124loss: tensor(0.8976)\n",
            "epoch: 125loss: tensor(0.8988)\n",
            "epoch: 126loss: tensor(0.9004)\n",
            "epoch: 127loss: tensor(0.8983)\n",
            "epoch: 128loss: tensor(0.8973)\n",
            "epoch: 129loss: tensor(0.8969)\n",
            "epoch: 130loss: tensor(0.8969)\n",
            "epoch: 131loss: tensor(0.8967)\n",
            "epoch: 132loss: tensor(0.8963)\n",
            "epoch: 133loss: tensor(0.8962)\n",
            "epoch: 134loss: tensor(0.8970)\n",
            "epoch: 135loss: tensor(0.8973)\n",
            "epoch: 136loss: tensor(0.8968)\n",
            "epoch: 137loss: tensor(0.8965)\n",
            "epoch: 138loss: tensor(0.8989)\n",
            "epoch: 139loss: tensor(0.8984)\n",
            "epoch: 140loss: tensor(0.8972)\n",
            "epoch: 141loss: tensor(0.8959)\n",
            "epoch: 142loss: tensor(0.8971)\n",
            "epoch: 143loss: tensor(0.8971)\n",
            "epoch: 144loss: tensor(0.8964)\n",
            "epoch: 145loss: tensor(0.8954)\n",
            "epoch: 146loss: tensor(0.8953)\n",
            "epoch: 147loss: tensor(0.8959)\n",
            "epoch: 148loss: tensor(0.8958)\n",
            "epoch: 149loss: tensor(0.8948)\n",
            "epoch: 150loss: tensor(0.8947)\n",
            "epoch: 151loss: tensor(0.8950)\n",
            "epoch: 152loss: tensor(0.8945)\n",
            "epoch: 153loss: tensor(0.8942)\n",
            "epoch: 154loss: tensor(0.8944)\n",
            "epoch: 155loss: tensor(0.8952)\n",
            "epoch: 156loss: tensor(0.8951)\n",
            "epoch: 157loss: tensor(0.8949)\n",
            "epoch: 158loss: tensor(0.8965)\n",
            "epoch: 159loss: tensor(0.8958)\n",
            "epoch: 160loss: tensor(0.8943)\n",
            "epoch: 161loss: tensor(0.8940)\n",
            "epoch: 162loss: tensor(0.8947)\n",
            "epoch: 163loss: tensor(0.8948)\n",
            "epoch: 164loss: tensor(0.8937)\n",
            "epoch: 165loss: tensor(0.8942)\n",
            "epoch: 166loss: tensor(0.8945)\n",
            "epoch: 167loss: tensor(0.8935)\n",
            "epoch: 168loss: tensor(0.8945)\n",
            "epoch: 169loss: tensor(0.8942)\n",
            "epoch: 170loss: tensor(0.8941)\n",
            "epoch: 171loss: tensor(0.8937)\n",
            "epoch: 172loss: tensor(0.8950)\n",
            "epoch: 173loss: tensor(0.8953)\n",
            "epoch: 174loss: tensor(0.8940)\n",
            "epoch: 175loss: tensor(0.8931)\n",
            "epoch: 176loss: tensor(0.8929)\n",
            "epoch: 177loss: tensor(0.8932)\n",
            "epoch: 178loss: tensor(0.8927)\n",
            "epoch: 179loss: tensor(0.8925)\n",
            "epoch: 180loss: tensor(0.8928)\n",
            "epoch: 181loss: tensor(0.8926)\n",
            "epoch: 182loss: tensor(0.8924)\n",
            "epoch: 183loss: tensor(0.8923)\n",
            "epoch: 184loss: tensor(0.8926)\n",
            "epoch: 185loss: tensor(0.8938)\n",
            "epoch: 186loss: tensor(0.8936)\n",
            "epoch: 187loss: tensor(0.8924)\n",
            "epoch: 188loss: tensor(0.8924)\n",
            "epoch: 189loss: tensor(0.8925)\n",
            "epoch: 190loss: tensor(0.8922)\n",
            "epoch: 191loss: tensor(0.8919)\n",
            "epoch: 192loss: tensor(0.8915)\n",
            "epoch: 193loss: tensor(0.8923)\n",
            "epoch: 194loss: tensor(0.8929)\n",
            "epoch: 195loss: tensor(0.8922)\n",
            "epoch: 196loss: tensor(0.8925)\n",
            "epoch: 197loss: tensor(0.8944)\n",
            "epoch: 198loss: tensor(0.8925)\n",
            "epoch: 199loss: tensor(0.8915)\n",
            "epoch: 200loss: tensor(0.8914)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the SAE\n",
        "\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "  input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "  target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "  if torch.sum(target.data > 0) > 0:\n",
        "    output = sae(input)\n",
        "    target.require_grad = False\n",
        "    output[target == 0] = 0\n",
        "    loss = criterion(output, target)\n",
        "    mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "    test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "    s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m_UjDsnTpdx",
        "outputId": "9fe95c7b-1a56-41f0-8740-c07e520011e1"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.9217)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a test loss of 0.92 i.e. our model is\n",
        "going to predict a rating that will be different from\n",
        "the real rating by less than one star.\n",
        "Our recommended system can predict for new movies\n",
        "if we are going to like it or not ie it will predict a rating close to the real rating.\n"
      ],
      "metadata": {
        "id": "h5D7rIBxlNiC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ueXRlw2AllKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}